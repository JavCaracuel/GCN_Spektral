{"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.11 64-bit ('CEIEC': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Carga_karate..ipynb","provenance":[{"file_id":"1czgF2sldadzAZ3Ez2sEzAiy5qA5kZpKC","timestamp":1632826011994}],"collapsed_sections":[]},"interpreter":{"hash":"45d704c04070b4f32eb97b779b2b19f2ebf3da5291fdb18b3bd409324536e139"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{}},{"cell_type":"markdown","source":["## librerias\r\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import tensorflow as tf\r\n","from sklearn.metrics.cluster import (\r\n","    completeness_score,\r\n","    homogeneity_score,\r\n","    v_measure_score,\r\n",")\r\n","from tensorflow.keras.layers import Input\r\n","from tensorflow.keras.models import Model\r\n","from tqdm import tqdm\r\n","\r\n","from spektral.datasets.citation import Cora\r\n","from spektral.layers.convolutional import GCSConv\r\n","from spektral.layers.pooling import MinCutPool\r\n","from spektral.utils.convolution import normalized_adjacency\r\n","from spektral.utils.sparse import sp_matrix_to_sp_tensor"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["@tf.function\r\n","def train_step(inputs):\r\n","    with tf.GradientTape() as tape:\r\n","        _, S_pool = model(inputs, training=True)\r\n","        loss = sum(model.losses)\r\n","    gradients = tape.gradient(loss, model.trainable_variables)\r\n","    opt.apply_gradients(zip(gradients, model.trainable_variables))\r\n","    return model.losses[0], model.losses[1], S_pool\r\n","\r\n","\r\n","np.random.seed(1)\r\n","epochs = 5000  # Training iterations\r\n","lr = 5e-4  # Learning rate\r\n","\r\n","################################################################################\r\n","# LOAD DATASET\r\n","################################################################################\r\n","dataset = Cora()\r\n","adj, x, y = dataset[0].a, dataset[0].x, dataset[0].y\r\n","a_norm = normalized_adjacency(adj)\r\n","a_norm = sp_matrix_to_sp_tensor(a_norm)\r\n","F = dataset.n_node_features\r\n","y = np.argmax(y, axis=-1)\r\n","n_clusters = y.max() + 1\r\n","\r\n","################################################################################\r\n","# MODEL\r\n","################################################################################\r\n","x_in = Input(shape=(F,), name=\"X_in\")\r\n","a_in = Input(shape=(None,), name=\"A_in\", sparse=True)\r\n","\r\n","x_1 = GCSConv(16, activation=\"elu\")([x_in, a_in])\r\n","x_1, a_1, s_1 = MinCutPool(n_clusters, return_mask=True)([x_1, a_in])\r\n","\r\n","model = Model([x_in, a_in], [x_1, s_1])\r\n","\r\n","################################################################################\r\n","# TRAINING\r\n","################################################################################\r\n","# Setup\r\n","inputs = [x, a_norm]\r\n","opt = tf.keras.optimizers.Adam(learning_rate=lr)\r\n","\r\n","# Fit model\r\n","loss_history = []\r\n","nmi_history = []\r\n","for _ in tqdm(range(epochs)):\r\n","    outs = train_step(inputs)\r\n","    outs = [o.numpy() for o in outs]\r\n","    loss_history.append((outs[0], outs[1], (outs[0] + outs[1])))\r\n","    s_out = np.argmax(outs[2], axis=-1)\r\n","    nmi_history.append(v_measure_score(y, s_out))\r\n","loss_history = np.array(loss_history)\r\n","\r\n","################################################################################\r\n","# RESULTS\r\n","################################################################################\r\n","_, s_out = model(inputs, training=False)\r\n","s_out = np.argmax(s_out, axis=-1)\r\n","hom = homogeneity_score(y, s_out)\r\n","com = completeness_score(y, s_out)\r\n","nmi = v_measure_score(y, s_out)\r\n","print(\"Homogeneity: {:.3f}; Completeness: {:.3f}; NMI: {:.3f}\".format(hom, com, nmi))\r\n","\r\n","# Plots\r\n","plt.figure(figsize=(10, 5))\r\n","\r\n","plt.subplot(121)\r\n","plt.plot(loss_history[:, 0], label=\"MinCUT loss\")\r\n","plt.plot(loss_history[:, 1], label=\"Ortho. loss\")\r\n","plt.plot(loss_history[:, 2], label=\"Total loss\")\r\n","plt.legend()\r\n","plt.ylabel(\"Loss\")\r\n","plt.xlabel(\"Iteration\")\r\n","\r\n","plt.subplot(122)\r\n","plt.plot(nmi_history, label=\"NMI\")\r\n","plt.legend()\r\n","plt.ylabel(\"NMI\")\r\n","plt.xlabel(\"Iteration\")\r\n","\r\n","plt.show()"],"outputs":[],"metadata":{}}]}